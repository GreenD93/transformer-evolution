{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8fbfd8eea8c47f48e1c2450c89f1f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56c558e517ad48cb9ecff4d93fc102ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_709d936a27f24720a6b2fe56f4182a5b",
              "IPY_MODEL_f179ccd4599d4204ab1583db1b4e7ad6"
            ]
          }
        },
        "56c558e517ad48cb9ecff4d93fc102ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "709d936a27f24720a6b2fe56f4182a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d00629fd7a5241e8ac4249007cae006f",
            "_dom_classes": [],
            "description": "Loading",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 3724301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1039716,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eceb795f3d6544688ce06962769cb2e2"
          }
        },
        "f179ccd4599d4204ab1583db1b4e7ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e64f4c29b6c4349b641ca81958b2b93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28% 1039716/3724301 [01:05&lt;02:47, 15983.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_797c7c3846654add9bb5e2cf6beb3126"
          }
        },
        "d00629fd7a5241e8ac4249007cae006f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eceb795f3d6544688ce06962769cb2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e64f4c29b6c4349b641ca81958b2b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "797c7c3846654add9bb5e2cf6beb3126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "077bf070e3d84aa1aadb13a999172d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fbd0ba8eedf40d382a1df7c638c07a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f61dfccc85f14d87b14631d4ab46c7ea",
              "IPY_MODEL_38cbd1b0ba41438cb4200a5d21a5b28d"
            ]
          }
        },
        "4fbd0ba8eedf40d382a1df7c638c07a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f61dfccc85f14d87b14631d4ab46c7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fac11e4e54af473fbf9f7b40d7e17fce",
            "_dom_classes": [],
            "description": "Making",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 100001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccbef01597344a90b5798723adc2978e"
          }
        },
        "38cbd1b0ba41438cb4200a5d21a5b28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ffecf54ef544bcfab8744c226e33714",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 100001/100001 [01:05&lt;00:00, 1538.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42e97022207348a6b71e70d87755f1ef"
          }
        },
        "fac11e4e54af473fbf9f7b40d7e17fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccbef01597344a90b5798723adc2978e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ffecf54ef544bcfab8744c226e33714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42e97022207348a6b71e70d87755f1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCF6eWlQGjH5",
        "colab_type": "text"
      },
      "source": [
        "## BERT 구현 과정 (1/2)\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2020-01-02/bert-pretrain.png)\n",
        "\n",
        "BERT 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcKmueewQQbf",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B9WSoPaG5va",
        "colab_type": "code",
        "outputId": "40e25132-855a-4989-8350-2a0d0e9bd8d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 32.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 34.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 19.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 18.3MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 16.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 16.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 15.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 15.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 15.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 15.3MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 15.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 15.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 15.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 15.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 15.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=1b52937c9e3d2eb740a16fbc914c031638bbbdd7f95c4eae9d15c148de04f832\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t57ZDrpQVPf",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo3kfdTxM_dx",
        "colab_type": "code",
        "outputId": "8c1f917c-d409-4a2a-c0fd-574ffb5e8b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K0u3OtaQcCG",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJFoQFbQfaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from random import random, randrange, randint, shuffle, choice\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuQJkP4FQ17R",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw9syi7mQ4Wf",
        "colab_type": "code",
        "outputId": "a9b5c862-71d4-4a61-e180-b6a1cee9ad7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n",
            "kowiki_gpt.json\n",
            "save_gpt_pretrain.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TEqHwEVQ7ch",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJk2o8ykRDNn",
        "colab_type": "code",
        "outputId": "e7e85036-fd93-48ba-c6e6-05aabe6fa22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cepm-CRzQ-Jf",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az1JWouiRAgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUBr9IYkRH8v",
        "colab_type": "code",
        "outputId": "7b48ed02-4f7c-4aa0-cee6-75a11904f701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yavmvonqRL5g",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Common Class\n",
        "공통으로 사용되는 Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY99m9lMRMy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rmgSjxPRPzK",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Encoder\n",
        "Encoder 입니다.\n",
        "\n",
        "표준 Transformer Encoder에서 BERT에서 추가된 정의한 segment embedding만 추가 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtfrgJ9ORcwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIrkxJ-SRrxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_hidn)\n",
        "        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_hidn)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cexyfhsQSHwK",
        "colab_type": "text"
      },
      "source": [
        "#### 8. BERT\n",
        "BERT 입니다.\n",
        "\n",
        "단순히 Transformer Encoder를 실행 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVOKzzvKSNjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" bert \"\"\"\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, self_attn_probs = self.encoder(inputs, segments)\n",
        "        # (bs, n_enc_seq, n_enc_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM9YREyBSU-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" BERT pretrain \"\"\"\n",
        "class BERTPretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BERT(self.config)\n",
        "        # classfier\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, 2, bias=False)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_enc_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.bert.encoder.enc_emb.weight\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, attn_probs = self.bert(inputs, segments)\n",
        "        # (bs, d_hidn)\n",
        "        outputs_cls = outputs[:, 0].contiguous()\n",
        "        # (bs, 2)\n",
        "        logits_cls = self.projection_cls(outputs_cls)\n",
        "        # (bs, n_enc_seq, n_enc_vocab)\n",
        "        logits_lm = self.projection_lm(outputs)\n",
        "        # (bs, n_enc_vocab), (bs, n_enc_seq, n_enc_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return logits_cls, logits_lm, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0411eNM9Sb1s",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Pretrain Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCjhydEqSc1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 마스크 생성 \"\"\"\n",
        "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
        "    cand_idx = []\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[-1].append(i)\n",
        "        else:\n",
        "            cand_idx.append([i])\n",
        "    shuffle(cand_idx)\n",
        "\n",
        "    mask_lms = []\n",
        "    for index_set in cand_idx:\n",
        "        if len(mask_lms) >= mask_cnt:\n",
        "            break\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
        "            continue\n",
        "        for index in index_set:\n",
        "            masked_token = None\n",
        "            if random() < 0.8: # 80% replace with [MASK]\n",
        "                masked_token = \"[MASK]\"\n",
        "            else:\n",
        "                if random() < 0.5: # 10% keep original\n",
        "                    masked_token = tokens[index]\n",
        "                else: # 10% random word\n",
        "                    masked_token = choice(vocab_list)\n",
        "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "            tokens[index] = masked_token\n",
        "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
        "    mask_label = [p[\"label\"] for p in mask_lms]\n",
        "\n",
        "    return tokens, mask_idx, mask_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dryud7_9Shvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 쵀대 길이 초과하는 토큰 자르기 \"\"\"\n",
        "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_seq:\n",
        "            break\n",
        "\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            del tokens_a[0]\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sCSQ0a6Sj-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" doc별 pretrain 데이터 생성 \"\"\"\n",
        "def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob, vocab_list):\n",
        "    # for CLS], [SEP], [SEP]\n",
        "    max_seq = n_seq - 3\n",
        "    tgt_seq = max_seq\n",
        "    \n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i]) # line\n",
        "        current_length += len(doc[i])\n",
        "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
        "            if 0 < len(current_chunk):\n",
        "                a_end = 1\n",
        "                if 1 < len(current_chunk):\n",
        "                    a_end = randrange(1, len(current_chunk))\n",
        "                tokens_a = []\n",
        "                for j in range(a_end):\n",
        "                    tokens_a.extend(current_chunk[j])\n",
        "                \n",
        "                tokens_b = []\n",
        "                if len(current_chunk) == 1 or random() < 0.5:\n",
        "                    is_next = 0\n",
        "                    tokens_b_len = tgt_seq - len(tokens_a)\n",
        "                    random_doc_idx = doc_idx\n",
        "                    while doc_idx == random_doc_idx:\n",
        "                        random_doc_idx = randrange(0, len(docs))\n",
        "                    random_doc = docs[random_doc_idx]\n",
        "\n",
        "                    random_start = randrange(0, len(random_doc))\n",
        "                    for j in range(random_start, len(random_doc)):\n",
        "                        tokens_b.extend(random_doc[j])\n",
        "                else:\n",
        "                    is_next = 1\n",
        "                    for j in range(a_end, len(current_chunk)):\n",
        "                        tokens_b.extend(current_chunk[j])\n",
        "\n",
        "                trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "                assert 0 < len(tokens_a)\n",
        "                assert 0 < len(tokens_b)\n",
        "\n",
        "                tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "                segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "                tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "                instance = {\n",
        "                    \"tokens\": tokens,\n",
        "                    \"segment\": segment,\n",
        "                    \"is_next\": is_next,\n",
        "                    \"mask_idx\": mask_idx,\n",
        "                    \"mask_label\": mask_label\n",
        "                }\n",
        "                instances.append(instance)\n",
        "\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY-6jSDsSuvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터 생성 \"\"\"\n",
        "def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\n",
        "    vocab_list = []\n",
        "    for id in range(vocab.get_piece_size()):\n",
        "        if not vocab.is_unknown(id):\n",
        "            vocab_list.append(vocab.id_to_piece(id))\n",
        "\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "    \n",
        "    docs = []\n",
        "    with open(in_file, \"r\") as f:\n",
        "        doc = []\n",
        "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "\n",
        "    for index in range(count):\n",
        "        output = out_file.format(index)\n",
        "        if os.path.isfile(output): continue\n",
        "\n",
        "        with open(output, \"w\") as out_f:\n",
        "            with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
        "                for i, doc in enumerate(docs):\n",
        "                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob, vocab_list)\n",
        "                    for instance in instances:\n",
        "                        out_f.write(json.dumps(instance))\n",
        "                        out_f.write(\"\\n\")\n",
        "                    pbar.update(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ihvSolSzoT",
        "colab_type": "code",
        "outputId": "1e8a3aa7-820c-4c78-bf9a-f5cf1197dbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "b8fbfd8eea8c47f48e1c2450c89f1f02",
            "56c558e517ad48cb9ecff4d93fc102ea",
            "709d936a27f24720a6b2fe56f4182a5b",
            "f179ccd4599d4204ab1583db1b4e7ad6",
            "d00629fd7a5241e8ac4249007cae006f",
            "eceb795f3d6544688ce06962769cb2e2",
            "2e64f4c29b6c4349b641ca81958b2b93",
            "797c7c3846654add9bb5e2cf6beb3126",
            "077bf070e3d84aa1aadb13a999172d00",
            "4fbd0ba8eedf40d382a1df7c638c07a1",
            "f61dfccc85f14d87b14631d4ab46c7ea",
            "38cbd1b0ba41438cb4200a5d21a5b28d",
            "fac11e4e54af473fbf9f7b40d7e17fce",
            "ccbef01597344a90b5798723adc2978e",
            "7ffecf54ef544bcfab8744c226e33714",
            "42e97022207348a6b71e70d87755f1ef"
          ]
        }
      },
      "source": [
        "in_file = f\"{data_dir}/kowiki.txt\"\n",
        "out_file = f\"{data_dir}/kowiki_bert\" + \"_{}.json\"\n",
        "count = 1\n",
        "n_seq = 256\n",
        "mask_prob = 0.15\n",
        "\n",
        "make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8fbfd8eea8c47f48e1c2450c89f1f02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading', max=3724301, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "077bf070e3d84aa1aadb13a999172d00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Making', max=100001, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WH8ygciLOsg",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Pretrain Data\n",
        "GPT Pretrain Data 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYQy0jh7LPlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터셋 \"\"\"\n",
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels_cls = []\n",
        "        self.labels_lm = []\n",
        "        self.sentences = []\n",
        "        self.segments = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                instance = json.loads(line)\n",
        "                self.labels_cls.append(instance[\"is_next\"])\n",
        "                sentences = [vocab.piece_to_id(p) for p in instance[\"tokens\"]]\n",
        "                self.sentences.append(sentences)\n",
        "                self.segments.append(instance[\"segment\"])\n",
        "                mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int)\n",
        "                mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int)\n",
        "                label_lm = np.full(len(sentences), dtype=np.int, fill_value=-1)\n",
        "                label_lm[mask_idx] = mask_label\n",
        "                self.labels_lm.append(label_lm)\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels_cls) == len(self.labels_lm)\n",
        "        assert len(self.labels_cls) == len(self.sentences)\n",
        "        assert len(self.labels_cls) == len(self.segments)\n",
        "        return len(self.labels_cls)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels_cls[item]),\n",
        "                torch.tensor(self.labels_lm[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor(self.segments[item]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPEpzcFmLZ-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain data collate_fn \"\"\"\n",
        "def pretrin_collate_fn(inputs):\n",
        "    labels_cls, labels_lm, inputs, segments = list(zip(*inputs))\n",
        "\n",
        "    labels_lm = torch.nn.utils.rnn.pad_sequence(labels_lm, batch_first=True, padding_value=-1)\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels_cls, dim=0),\n",
        "        labels_lm,\n",
        "        inputs,\n",
        "        segments\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7wrvZVOLca8",
        "colab_type": "code",
        "outputId": "06da013c-c870-42f1-b921-d12c1823bcb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\" pretrain 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_0.json\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Data/transformer-evolution/kowiki_bert_0.json: 100%|██████████| 239857/239857 [00:55<00:00, 4327.87 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yERFmhF-LmKM",
        "colab_type": "text"
      },
      "source": [
        "#### 11. Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN9IHtGBLm5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels_cls, labels_lm, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_cls, logits_lm = outputs[0], outputs[1]\n",
        "\n",
        "            loss_cls = criterion_cls(logits_cls, labels_cls)\n",
        "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
        "            loss = loss_cls + loss_lm\n",
        "\n",
        "            loss_val = loss_lm.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFfDno62MCCb",
        "colab_type": "code",
        "outputId": "ee2a5c8d-a26f-4ca8-c84e-fc97f124552f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkofvdbFMEX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTPretrain(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_bert_pretrain.pth\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "if os.path.isfile(save_pretrain):\n",
        "    best_epoch, best_loss = model.bert.load(save_pretrain)\n",
        "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "    best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
        "criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in range(n_epoch):\n",
        "    epoch = step + offset\n",
        "    if 0 < step:\n",
        "        del train_loader\n",
        "        dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_{epoch % count}.json\")\n",
        "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)\n",
        "\n",
        "    loss = train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    model.bert.save(epoch, loss, save_pretrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FFSPSlQMn29",
        "colab_type": "code",
        "outputId": "98dec0bb-80dc-4199-990e-c10ec5e3acee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        }
      },
      "source": [
        "# data\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.484688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.871636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.334166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.021088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.915976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.864175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.830710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.806665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.789094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.775770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.763113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.752536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.743481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.737807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.729479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.725570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6.719991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6.714533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.712154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.710058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss\n",
              "0   18.484688\n",
              "1    8.871636\n",
              "2    7.334166\n",
              "3    7.021088\n",
              "4    6.915976\n",
              "5    6.864175\n",
              "6    6.830710\n",
              "7    6.806665\n",
              "8    6.789094\n",
              "9    6.775770\n",
              "10   6.763113\n",
              "11   6.752536\n",
              "12   6.743481\n",
              "13   6.737807\n",
              "14   6.729479\n",
              "15   6.725570\n",
              "16   6.719991\n",
              "17   6.714533\n",
              "18   6.712154\n",
              "19   6.710058"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAEGCAYAAACeiKhrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuP36orM6owAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}